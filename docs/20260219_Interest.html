<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Interest — 19th February 2026</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<style>
  :root {
    --ink: #1b1f23; --muted: #666; --rule: #eee; --accent: #004aad;
  }
  body { font: 16px/1.6 system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;
         margin: 2rem auto; max-width: 900px; padding: 0 1rem; color: var(--ink); }
  h1 { margin: 0 0 .25rem 0; font-size: 1.8rem; }
  .sub { color: var(--muted); margin: 0 0 1.25rem 0; }
  h2 { margin: 1.5rem 0 .5rem; font-size: 1.15rem; color: var(--muted); font-weight: 600; }
  article { padding: .75rem 0; border-top: 1px solid var(--rule); }
  a.title { text-decoration: none; font-weight: 600; color: inherit; }
  a.title:hover { text-decoration: underline; color: var(--accent); }
  .id { color:#999; font-size:.9rem; margin-left:.5rem; }
  details { margin-top: .35rem; }
  summary { cursor: pointer; color: var(--accent); outline: none; }
  .num { font-variant-numeric: tabular-nums; width: 2.25rem; display:inline-block; color:#999; }
</style>

    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        packages: {'[+]': ['textmacros']}
      },
      options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
    };
    </script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</head>
<body>
<h1>Interest</h1>
<div class="sub">19th February 2026 · History &amp; Philosophy of Physics; Physics Education · 3 entries</div>
<h2>History &amp; Philosophy of Physics</h2><article><div><span class="num"> 1.</span> <a class="title" href="https://arxiv.org/abs/2602.16495" target="_blank" rel="noopener noreferrer">General formalism, classification, and demystification of the current warp-drive spacetimes</a><span class="id">[2602.16495]</span></div><details><summary>Abstract</summary><div><p>We critically examine proposals for the so-called warp-drive spacetimes and classify these models based on their various restrictions within the framework of General Relativity. We then provide a summary of general formalism for each class, and in the process, we highlight some misconceptions, misunderstandings, and errors in the literature that have been used to support claims about the physicality and feasibility of these models. On the way, we prove several new no-go theorems. Our analysis shows that when the principles of General Relativity are applied correctly, most claims regarding physical warp drives must be reassessed, and it becomes highly challenging to justify or support the viability of such models, not merely due to the violation of energy conditions.</p></div></details></article>
<h2>Physics Education</h2><article><div><span class="num"> 2.</span> <a class="title" href="https://arxiv.org/abs/2602.15889" target="_blank" rel="noopener noreferrer">Evidence for Daily and Weekly Periodic Variability in GPT-4o Performance</a><span class="id">[2602.15889]</span></div><details><summary>Abstract</summary><div><p>Large language models (LLMs) are increasingly used in research both as tools and as objects of investigation. Much of this work implicitly assumes that LLM performance under fixed conditions (identical model snapshot, hyperparameters, and prompt) is time-invariant. If average output quality changes systematically over time, this assumption is violated, threatening the reliability, validity, and reproducibility of findings. To empirically examine this assumption, we conducted a longitudinal study on the temporal variability of GPT-4o's average performance. Using a fixed model snapshot, fixed hyperparameters, and identical prompting, GPT-4o was queried via the API to solve the same multiple-choice physics task every three hours for approximately three months. Ten independent responses were generated at each time point and their scores were averaged. Spectral (Fourier) analysis of the resulting time series revealed notable periodic variability in average model performance, accounting for approximately 20% of the total variance. In particular, the observed periodic patterns are well explained by the interaction of a daily and a weekly rhythm. These findings indicate that, even under controlled conditions, LLM performance may vary periodically over time, calling into question the assumption of time invariance. Implications for ensuring validity and replicability of research that uses or investigates LLMs are discussed.</p></div></details></article><article><div><span class="num"> 3.</span> <a class="title" href="https://arxiv.org/abs/2511.10515" target="_blank" rel="noopener noreferrer">Mastering Olympiad-Level Physics with Artificial Intelligence</a><span class="id">[2511.10515]</span></div><details><summary>Abstract</summary><div><p>Olympiad-level physics problem-solving significantly challenges both humans and artificial intelligence (AI), as it requires integrating appropriate modeling, application of physical principles, and precise calculation within long reasoning processes. In this paper, we introduce LOCA (LOgical Chain Augmentation), an AI agent framework designed for complex physics reasoning. LOCA decomposes long reasoning into serialized atomic and verifiable steps, refining the solution through an augment-review loop. We evaluate LOCA on the 2025 Chinese Physics Olympiad (CPhO) theory examination, a rigorous testbed renowned for its depth and complexity. The framework achieves a near-perfect score of 313 out of 320 points, significantly surpassing the top human competitor and other baseline methods. Furthermore, LOCA attains a near-perfect score of 28.6 out of 30 on the IPhO 2025 examination, demonstrating its strong generalizability across different contexts. Our work points toward the development of trustworthy AI partners in both research and education.</p></div></details></article></body>
</html>