<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Interest — 17th November 2025</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<style>
  :root {
    --ink: #1b1f23; --muted: #666; --rule: #eee; --accent: #004aad;
  }
  body { font: 16px/1.6 system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;
         margin: 2rem auto; max-width: 900px; padding: 0 1rem; color: var(--ink); }
  h1 { margin: 0 0 .25rem 0; font-size: 1.8rem; }
  .sub { color: var(--muted); margin: 0 0 1.25rem 0; }
  h2 { margin: 1.5rem 0 .5rem; font-size: 1.15rem; color: var(--muted); font-weight: 600; }
  article { padding: .75rem 0; border-top: 1px solid var(--rule); }
  a.title { text-decoration: none; font-weight: 600; color: inherit; }
  a.title:hover { text-decoration: underline; color: var(--accent); }
  .id { color:#999; font-size:.9rem; margin-left:.5rem; }
  details { margin-top: .35rem; }
  summary { cursor: pointer; color: var(--accent); outline: none; }
  .num { font-variant-numeric: tabular-nums; width: 2.25rem; display:inline-block; color:#999; }
</style>

    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        packages: {'[+]': ['textmacros']}
      },
      options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
    };
    </script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</head>
<body>
<h1>Interest</h1>
<div class="sub">17th November 2025 · Physics Education · 2 entries</div>
<h2>Physics Education</h2><article><div><span class="num"> 1.</span> <a class="title" href="https://arxiv.org/abs/2511.11317" target="_blank" rel="noopener noreferrer">How Physics Professors Use and Frame Generative AI Tools</a><span class="id">[2511.11317]</span></div><details><summary>Abstract</summary><div><p>Generative AI is rapidly reshaping how physicists teach, learn, and conduct research, yet little is known about how physics faculty are responding to these changes. We interviewed 12 physics professors at a major Scandinavian research university to explore their uses and perceptions of Generative AI (GenAI) in both teaching and research. Using the theoretical framework of epistemic framing, we conducted a thematic analysis that identified 19 overlapping practices, ranging from coding and literature review to assessment and feedback. From these practices, we derived six overlapping epistemic frames through which professors make sense of GenAI: as a threat to genuine learning and assessment, a source of knowledge, a discussion partner, a text-processing tool, a coding tool, and a labor-saving device. While the latter five position GenAI as a useful tool in the physicists' toolbox, the threat frame represented an overarching concern that colored all other frames. These findings reveal how GenAI is beginning to transform what it means to be a physicist, highlighting both opportunities for innovation and challenges for academic integrity and learning.</p></div></details></article><article><div><span class="num"> 2.</span> <a class="title" href="https://arxiv.org/abs/2504.08910" target="_blank" rel="noopener noreferrer">Assessing Physics Students' Scientific Argumentation using Natural Language Processing</a><span class="id">[2504.08910]</span></div><details><summary>Abstract</summary><div><p>Scientific argumentation is a core science and engineering practice and a necessary 21st Century workforce skill. Due to the nature of large enrollment classes, it is difficult to individually assess students and provide feedback on their scientific argumentation. The recent developments in Natural Language Processing (NLP) and Machine Learning (ML) provide new opportunities to analyze large collections of student writing efficiently. In this study, we investigate how undergraduate students' scientific argumentation evolves across four semesters of an introductory calculus-based physics course as increasingly structured argumentation scaffolds were introduced. We investigate the use of NLP and ML, specifically topic modeling, to analyze student scientific argumentation across those semesters. We report on the emergent themes present in each semester. Our findings show a clear shift in the thematic focus of student arguments corresponding to the level of scaffolding provided. In semesters with minimal scaffolding, students' arguments emphasized procedural and surface-level features, while semesters with explicit scaffolds exhibited greater concentration around physics-principle-based themes. These results suggest that structured scaffolding supports students in constructing more conceptually grounded scientific arguments and highlights the potential of NLP and ML as scalable approaches for evaluate broad trends in students' scientific argumentation.</p></div></details></article></body>
</html>